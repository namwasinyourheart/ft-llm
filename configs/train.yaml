
exp_name: "it__qwen2.5-0.5b-instruct__cmc_global_qa_480"
seed: 202412

model_args:
    pretrained_model_name_or_path: "Qwen/Qwen2.5-0.5B-Instruct"
    load_in_4bit: true
    load_in_8bit: false
    bnb_4bit_compute_dtype: 
    bnb_4bit_quant_type: "nf4"
    bnb_4bit_use_double_quant: false
    bnb_4bit_quant_storage: "uint8"


    use_peft: True
    lora:
      r: 64
      lora_alpha: 32
      lora_dropout: 0.0
      bias: none
      task_type: CAUSAL_LM
      inference_mode: false
      target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj


train_args:
    _target_: transformers.TrainingArguments
    _convert_: all
    resume_from_checkpoint: true
    do_train: true
    do_eval: true
    do_predict: true
    learning_rate: 0.0001
    num_train_epochs: 1
    per_device_train_batch_size: 2
    per_device_eval_batch_size: 2
    logging_steps: 1
    logging_first_step: true
    save_strategy: epoch
    eval_strategy: epoch
    eval_on_start: true
