{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\projects\\ft-llm-tp\n"
     ]
    }
   ],
   "source": [
    "cd E:/projects/ft-llm-tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'E:/projects/ft-llm-tp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.model_utils import load_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Args:\n",
      "exp_manager:\n",
      "  seed: 202412\n",
      "  exps_dir: ./exps\n",
      "  exp_name: it__qwen2.5-0.5b-instruct__cmc_global_qa_480\n",
      "  prepare_data_cfg_path: configs/prepare_data.yaml\n",
      "  train_cfg_path: configs/train.yaml\n",
      "  task_name: null\n",
      "  model_name: null\n",
      "  dataset_name: null\n",
      "wandb:\n",
      "  use_wandb: true\n",
      "  project: llm_ft_ask_cmc_global\n",
      "\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exp_manager': {'seed': 202412, 'exps_dir': './exps', 'exp_name': 'it__qwen2.5-0.5b-instruct__cmc_global_qa_480', 'prepare_data_cfg_path': 'configs/prepare_data.yaml', 'train_cfg_path': 'configs/train.yaml', 'task_name': None, 'model_name': None, 'dataset_name': None}, 'wandb': {'use_wandb': True, 'project': 'llm_ft_ask_cmc_global'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_args('configs/exp.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Args:\n",
      "dataset:\n",
      "  data_path: E:/projects/ask-aimesoft/notebooks/draft/list_qa_results_20241209_024009_fixed_row8_list_type.csv\n",
      "  do_split: true\n",
      "  val_ratio: 0.25\n",
      "  test_ratio: 0.2\n",
      "  output_path: null\n",
      "prompt:\n",
      "  use_model_chat_template: true\n",
      "  instruction_key: '### Instruction:'\n",
      "  instruction_text: You are a knowledgeable assistant for the company CMC Global.\n",
      "    Your task is to providing accurate and helpful answers to the user's questions\n",
      "    about the company.\n",
      "  input_key: '### Question:'\n",
      "  response_key: '### Answer:'\n",
      "  end_key: null\n",
      "tokenizer:\n",
      "  model_name_or_path: Qwen/Qwen2.5-0.5B-Instruct\n",
      "  new_pad_token: null\n",
      "  do_tokenize: false\n",
      "  truncation: true\n",
      "  padding: max_length\n",
      "  add_special_tokens: true\n",
      "  max_length: 128\n",
      "\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_data_args = load_args('configs/prepare_data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': 'E:/projects/ask-aimesoft/notebooks/draft/list_qa_results_20241209_024009_fixed_row8_list_type.csv', 'do_split': True, 'val_ratio': 0.25, 'test_ratio': 0.2, 'output_path': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data_args.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Args:\n",
      "exp_name: it__qwen2.5-0.5b-instruct__cmc_global_qa_480\n",
      "seed: 202412\n",
      "model_args:\n",
      "  pretrained_model_name_or_path: Qwen/Qwen2.5-0.5B-Instruct\n",
      "  load_in_4bit: true\n",
      "  load_in_8bit: false\n",
      "  bnb_4bit_compute_dtype: null\n",
      "  bnb_4bit_quant_type: nf4\n",
      "  bnb_4bit_use_double_quant: false\n",
      "  bnb_4bit_quant_storage: uint8\n",
      "use_peft: true\n",
      "lora:\n",
      "  r: 64\n",
      "  lora_alpha: 32\n",
      "  lora_dropout: 0.0\n",
      "  bias: none\n",
      "  task_type: CAUSAL_LM\n",
      "  inference_mode: false\n",
      "  target_modules:\n",
      "  - q_proj\n",
      "  - k_proj\n",
      "  - v_proj\n",
      "  - o_proj\n",
      "  - gate_proj\n",
      "  - up_proj\n",
      "  - down_proj\n",
      "train_args:\n",
      "  _target_: transformers.TrainingArguments\n",
      "  resume_from_checkpoint: true\n",
      "  do_train: true\n",
      "  do_eval: true\n",
      "  do_predict: true\n",
      "  learning_rate: 0.0001\n",
      "  num_train_epochs: 1\n",
      "  per_device_train_batch_size: 2\n",
      "  per_device_eval_batch_size: 2\n",
      "  logging_steps: 1\n",
      "  logging_first_step: true\n",
      "  save_strategy: epoch\n",
      "  eval_strategy: epoch\n",
      "  eval_on_start: true\n",
      "\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_args = load_args('configs/train.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = train_args.model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.model_utils import load_model, load_tokenizer, get_model_tokenizer, get_peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7eb1458c4834700bf57fd76c0bff8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = load_tokenizer(prepare_data_args, model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moel = load_model(model_args, use_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = get_model_tokenizer(prepare_data_args, model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Config {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
       "  \"architectures\": [\n",
       "    \"Qwen2ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"eos_token_id\": 151645,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 896,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4864,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"max_window_layers\": 21,\n",
       "  \"model_type\": \"qwen2\",\n",
       "  \"num_attention_heads\": 14,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": true,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.47.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 151665\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151665"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"E:/projects/ask-aimesoft/notebooks/draft/list_qa_results_20241209_024009_fixed_row8_list_type.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>company_overview__qa1</td>\n",
       "      <td>company_overview</td>\n",
       "      <td>CMC Global cung cấp giải pháp gì cho khách hàng?</td>\n",
       "      <td>CMC Global cung cấp giải pháp IT một cửa, bao ...</td>\n",
       "      <td>https://cmcglobal.com.vn/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company_overview__qa2</td>\n",
       "      <td>company_overview</td>\n",
       "      <td>Giải pháp IT Outsourcing của CMC Global mang l...</td>\n",
       "      <td>Giải pháp IT Outsourcing của CMC Global giúp c...</td>\n",
       "      <td>https://cmcglobal.com.vn/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company_overview__qa3</td>\n",
       "      <td>company_overview</td>\n",
       "      <td>CMC Global hỗ trợ chuyển đổi số như thế nào?</td>\n",
       "      <td>CMC Global hỗ trợ việc áp dụng các công nghệ t...</td>\n",
       "      <td>https://cmcglobal.com.vn/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>company_overview__qa4</td>\n",
       "      <td>company_overview</td>\n",
       "      <td>Dịch vụ nào thuộc danh mục giải pháp của CMC G...</td>\n",
       "      <td>Các dịch vụ thuộc danh mục giải pháp của CMC G...</td>\n",
       "      <td>https://cmcglobal.com.vn/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company_overview__qa5</td>\n",
       "      <td>company_overview</td>\n",
       "      <td>Các giải pháp CMC Global có gì đặc biệt?</td>\n",
       "      <td>Giải pháp của CMC Global bao gồm các dịch vụ c...</td>\n",
       "      <td>https://cmcglobal.com.vn/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>customer_support__qa16</td>\n",
       "      <td>customer_support</td>\n",
       "      <td>Mọi văn phòng ở Tokyo đều có số điện thoại giố...</td>\n",
       "      <td>Có, tất cả các văn phòng ở Tokyo đều có số điệ...</td>\n",
       "      <td>https://cmcglobal.com.vn/contact-us/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>customer_support__qa17</td>\n",
       "      <td>customer_support</td>\n",
       "      <td>Có văn phòng nào ở hải ngoại không?</td>\n",
       "      <td>Có, công ty có văn phòng tại Tokyo và Singapor...</td>\n",
       "      <td>https://cmcglobal.com.vn/contact-us/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>customer_support__qa18</td>\n",
       "      <td>customer_support</td>\n",
       "      <td>Công ty có văn phòng nào ở khu vực trung tâm Đ...</td>\n",
       "      <td>Có, văn phòng ở Đà Nẵng nằm ngay tại trung tâm...</td>\n",
       "      <td>https://cmcglobal.com.vn/contact-us/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>customer_support__qa19</td>\n",
       "      <td>customer_support</td>\n",
       "      <td>Văn phòng nào có địa chỉ cụ thể tại quận Jung-gu?</td>\n",
       "      <td>Văn phòng ở Seoul có địa chỉ cụ thể tại quận J...</td>\n",
       "      <td>https://cmcglobal.com.vn/contact-us/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>customer_support__qa20</td>\n",
       "      <td>customer_support</td>\n",
       "      <td>Có cần phải đặt lịch hẹn trước khi đến văn phò...</td>\n",
       "      <td>Thông tin này không được cung cấp trong nội du...</td>\n",
       "      <td>https://cmcglobal.com.vn/contact-us/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      qa_id     question_type  \\\n",
       "0     company_overview__qa1  company_overview   \n",
       "1     company_overview__qa2  company_overview   \n",
       "2     company_overview__qa3  company_overview   \n",
       "3     company_overview__qa4  company_overview   \n",
       "4     company_overview__qa5  company_overview   \n",
       "..                      ...               ...   \n",
       "475  customer_support__qa16  customer_support   \n",
       "476  customer_support__qa17  customer_support   \n",
       "477  customer_support__qa18  customer_support   \n",
       "478  customer_support__qa19  customer_support   \n",
       "479  customer_support__qa20  customer_support   \n",
       "\n",
       "                                              question  \\\n",
       "0     CMC Global cung cấp giải pháp gì cho khách hàng?   \n",
       "1    Giải pháp IT Outsourcing của CMC Global mang l...   \n",
       "2         CMC Global hỗ trợ chuyển đổi số như thế nào?   \n",
       "3    Dịch vụ nào thuộc danh mục giải pháp của CMC G...   \n",
       "4             Các giải pháp CMC Global có gì đặc biệt?   \n",
       "..                                                 ...   \n",
       "475  Mọi văn phòng ở Tokyo đều có số điện thoại giố...   \n",
       "476                Có văn phòng nào ở hải ngoại không?   \n",
       "477  Công ty có văn phòng nào ở khu vực trung tâm Đ...   \n",
       "478  Văn phòng nào có địa chỉ cụ thể tại quận Jung-gu?   \n",
       "479  Có cần phải đặt lịch hẹn trước khi đến văn phò...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    CMC Global cung cấp giải pháp IT một cửa, bao ...   \n",
       "1    Giải pháp IT Outsourcing của CMC Global giúp c...   \n",
       "2    CMC Global hỗ trợ việc áp dụng các công nghệ t...   \n",
       "3    Các dịch vụ thuộc danh mục giải pháp của CMC G...   \n",
       "4    Giải pháp của CMC Global bao gồm các dịch vụ c...   \n",
       "..                                                 ...   \n",
       "475  Có, tất cả các văn phòng ở Tokyo đều có số điệ...   \n",
       "476  Có, công ty có văn phòng tại Tokyo và Singapor...   \n",
       "477  Có, văn phòng ở Đà Nẵng nằm ngay tại trung tâm...   \n",
       "478  Văn phòng ở Seoul có địa chỉ cụ thể tại quận J...   \n",
       "479  Thông tin này không được cung cấp trong nội du...   \n",
       "\n",
       "                                      url  \n",
       "0               https://cmcglobal.com.vn/  \n",
       "1               https://cmcglobal.com.vn/  \n",
       "2               https://cmcglobal.com.vn/  \n",
       "3               https://cmcglobal.com.vn/  \n",
       "4               https://cmcglobal.com.vn/  \n",
       "..                                    ...  \n",
       "475  https://cmcglobal.com.vn/contact-us/  \n",
       "476  https://cmcglobal.com.vn/contact-us/  \n",
       "477  https://cmcglobal.com.vn/contact-us/  \n",
       "478  https://cmcglobal.com.vn/contact-us/  \n",
       "479  https://cmcglobal.com.vn/contact-us/  \n",
       "\n",
       "[480 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prepare_data import has_system_role_support\n",
    "has_system_role_support(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedTokenizer\n",
    "from typing import Tuple\n",
    "\n",
    "def load_tokenizer(data_args, model_args,\n",
    "                  # padding_side\n",
    ") -> PreTrainedTokenizer:\n",
    "    tokenizer =  AutoTokenizer.from_pretrained(model_args.pretrained_model_name_or_path)\n",
    "\n",
    "    if not tokenizer.pad_token:\n",
    "        if data_args.new_pad_token:\n",
    "            tokenizer.padding_side = 'left'\n",
    "            tokenizer.pad_token = data_args.new_pad_token,\n",
    "            tokenizer.add_special_tokens({\"pad_token\": data_args.new_pad_token})\n",
    "        else:\n",
    "            tokenizer.padding_side = 'right'\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151665"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = load_tokenizer(prepare_data_args, model_args)\n",
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction:'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data_args.prompt.instruction_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTION_KEY = prepare_data_args.prompt.instruction_key\n",
    "INPUT_KEY = prepare_data_args.prompt.input_key\n",
    "RESPONSE_KEY = prepare_data_args.prompt.response_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\"additional_special_tokens\": [INPUT_KEY, INSTRUCTION_KEY, RESPONSE_KEY]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151668"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-0.5B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['### Question:', '### Instruction:', '### Answer:']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151665: AddedToken(\"### Question:\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151666: AddedToken(\"### Instruction:\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151667: AddedToken(\"### Answer:\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151668"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ft-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
